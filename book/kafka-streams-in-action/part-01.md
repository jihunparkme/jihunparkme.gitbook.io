# Part 1. 카프카 스트림즈 시작하기

## 카프카 스트림즈

👉🏻 **빅데이터로의 전환**

빅데이터로의 전환으로 대량의 데이터를 벌크 처리할 수 있는 능력만으로는 충분하지 않다.

`카프카 스트림즈`는 이벤트별 레코드 처리를 수행할 수 있게 하는 라이브러리다.

.

👉🏻 **스트림 처리를 사용해야 할 경우와 사용하지 말아야 할 경우**

데이터에 신속하게 응답하거나 보고해야 하는 경우가 스트림 처리의 좋은 사용 사례
- 신용카드 사기(고정 패턴-위치, 소비 습관)
- 침입 탐지(비정상적인 동작 모니터링)
- 뉴욕시 마라톤과 같은 대규모 경주(센서 데이터 사용)
- 금융 업계(시장 가격과 방향 추적)

데이터가 도착하자마자 즉시 보고하거나 조치를 취해야 하는 경우 스트림 처리가 좋은 방법이다.

.

👉🏻 **구매 트랜잭션에서의 관점**

![Result](https://github.com/jihunparkme/jihunparkme.gitbook.io/blob/main/.gitbook/assets/kafka-streams-in-action/example-stream.png?raw=true 'Result')

📖 **요약**

> 카프카 스트림즈는 강력하고 복잡한 스틀미 처리를 위해 처리 노드를 조합한 그래프
> 
> 배치 처리는 강력하지만 데이터 작업에 대한 실시간 요구를 만족시키기에는 충분하지 않음
>
> 데이터, 키/값 쌍, 파티셔닝 및 데이터 복제를 분산하는 것은 분산 애플리케이션에서 매우 중요

## 카프카 빠르게 살펴보기

카프카는
- 내고장성(fault-tolerant)을 가진 견고한 `발행/구독 시스템`
- 하나의 카프카 노드를 `bloker`라 부르고, 여러 개의 가프카 브로커 서버가 `cluster`를 구성
- 카프카는 `producer`가 작성한 메시지를 토픽에 저장
- `consumer`는 토픽을 구독하며, 구독한 토픽에 메시지가 있는지 확인하기 위해 카프카에 접속

```text
데이터 허브로 카프카를 사용하면 아키텍처가 훨씬 간단해진다.
각 애플리케이션은 카프카에 읽고 쓰는 방법만 알고 있으면 된다.
애플리케이션을 추가하거나 제거해도 다른 애플리케이션의 데이터 처리에 영향을 주지 않는다.
```

.

👉🏻 **구매 트랜잭션에서의 관점**