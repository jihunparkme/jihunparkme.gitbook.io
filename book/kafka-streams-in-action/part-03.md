# Part 3. ì¹´í”„ì¹´ ìŠ¤íŠ¸ë¦¼ì¦ˆ ê´€ë¦¬

**Table of contents**
- ê¸°ë³¸ì ì¸ ì¹´í”„ì¹´ ëª¨ë‹ˆí„°ë§
  - ì¸í„°ì…‰í„°
- ë©”íŠ¸ë¦­
- ì¹´í”„ì¹´ ìŠ¤íŠ¸ë¦¼ì¦ˆ ë””ë²„ê¹… ê¸°ìˆ 

# 7ì¥. ëª¨ë‹ˆí„°ë§ê³¼ ì„±ëŠ¥

## ê¸°ë³¸ì ì¸ ì¹´í”„ì¹´ ëª¨ë‹ˆí„°ë§

ì¹´í”„ì¹´ ìŠ¤íŠ¸ë¦¼ì¦ˆ APIëŠ” ì¹´í”„ì¹´ì˜ ì¼ë¶€ì´ë¯€ë¡œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ëª¨ë‹ˆí„°ë§í•  ë•Œ ì¹´í”„ì¹´ë„ ì¼ë¶€ ëª¨ë‹ˆí„°ë§í•´ì•¼ í•œë‹¤.

[Monitoring](https://kafka.apache.org/documentation/#monitoring)

.

ğŸ‘‰ğŸ» **ì»¨ìŠˆë¨¸ì™€ í”„ë¡œë“€ì„œ ì„±ëŠ¥ ì¸¡ì •**
- í”„ë¡œë“€ì„œì™€ ì»¨ìŠˆë¨¸ì˜ ì„±ëŠ¥ì€ ì²˜ë¦¬ëŸ‰ê³¼ ê´€ë ¨ì´ ìˆë‹¤.
- `í”„ë¡œë“€ì„œ`ì˜ ê²½ìš° í”„ë¡œë“€ì„œê°€ ì–¼ë§ˆë‚˜ ë¹ ë¥´ê²Œ ë¸Œë¡œì»¤ë¡œ ë©”ì‹œì§€ë¥¼ ë³´ë‚´ëŠëƒê°€ í° ê´€ì‹¬ì‚¬
  - ë¶„ëª… ì²˜ë¦¬ëŸ‰ì´ ë†’ìœ¼ë©´ ë†’ì„ìˆ˜ë¡ ë” ë‚®ë‹¤
- `ì»¨ìŠˆë¨¸`ì˜ ê²½ìš° ë¸Œë¡œì»¤ì—ì„œ ì–¼ë§ˆë‚˜ ë¹ ë¥´ê²Œ ë©”ì‹œì§€ë¥¼ ì½ì„ ìˆ˜ ìˆëŠëƒê°€ ì„±ëŠ¥ì— ì˜í–¥
  - ì»¨ìŠˆë¨¸ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ëŠ” ë˜ ë‹¤ë¥¸ ë°©ë²•ì€ ì»¨ìŠˆë¨¸ ì§€ì—°
- í”„ë¡œë“€ì„œê°€ ë¸Œë¡œì»¤ì— ê¸°ë¡í•˜ëŠ” ì†ë„ì™€ ì»¨ìŠˆë¨¸ê°€ ë©”ì‹œì§€ë¥¼ ì½ëŠ” ì†ë„ ì°¨ì´ë¥¼ `ì»¨ìŠˆë¨¸ ì§€ì—°`ì´ë¼ê³  ë¶€ë¥¸ë‹¤

.

ğŸ‘‰ğŸ» **ì»¨ìŠˆë¨¸ ì§€ì—° í™•ì¸í•˜ê¸°**
- ì»¨ìŠˆë¨¸ ì§€ì—°ì„ í™•ì¸í•˜ê¸° ìœ„í•´ ì¹´í”„ì¹´ëŠ” í¸ë¦¬í•œ ëª…ë ¹ì¤„ ë„êµ¬ë¥¼ ì œê³µ
  - kafka-consumer-groups.sh
- í™œì„±í™” ìƒíƒœì˜ ëª¨ë“  ì»¨ìŠˆë¨¸ ê·¸ë£¹ì„ ì°¾ê¸° ìœ„í•´ `list` ëª…ë ¹ì„ ì‚¬ìš©
  
```bash
kafka-installed-path/bin/kafka-consumer-groups.sh
                --bootstrap-server localhost:9092
                --list
```

- ì¡°íšŒí•  ì»¨ìŠˆë¨¸ ê·¸ë£¹ ì´ë¦„ì„ ì„ íƒí•˜ê³  ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰

```bash
kafka-installed-path/bin/kafka-consumer-groups.sh
            --bootstrap-server localhost:9092
            --group GROUP-NAME
            --describe
```

- ì‘ì€ ì§€ì—°ì´ë‚˜ ì¼ì •í•œ ì§€ì—°ì€ ë¬¸ì œê°€ ì•ˆ ë˜ì§€ë§Œ, ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ ê³„ì† ì¦ê°€í•˜ëŠ” ì§€ì—°ì€ ì»¨ìŠˆë¨¸ì—ê²Œ ë” ë§ì€ ë¦¬ì†ŒìŠ¤ë¥¼ ì œê³µí•´ì•¼ í•œë‹¤

.

ğŸ‘‰ğŸ» **í”„ë¡œë“€ì„œì™€ ì»¨ìŠˆë¨¸ ê°€ë¡œì±„ê¸°**

- `ì¸í„°ì…‰í„°`ëŠ” ë””ë²„ê¹…ì„ ìœ„í•œ ì¼ë°˜ì ì¸ ì œì¼ì„  ë„êµ¬ëŠ” ì•„ë‹ˆì§€ë§Œ ì¹´í”„ì¹´ ìŠ¤íŠ¸ë¦¬ë° ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ë™ì‘ì„ ê´€ì°°í•˜ëŠ” ë° ìœ ìš©í•  ìˆ˜ ìˆìœ¼ë©°, ìì‹ ë§Œì˜ ë„êµ¬ ì„¸íŠ¸ì— ì¶”ê°€í•  ë§Œí•œ ìœ ìš©í•œ ë„êµ¬ì´ë‹¤.
- `ì¸í„°ì…‰í„°`ë¥¼ ì‚¬ìš©í•˜ëŠ” ì¢‹ì€ ì˜ˆì œëŠ” ì¹´í”„ì¹´ ìŠ¤íŠ¸ë¦¼ì¦ˆ ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ì¹´í”„ì¹´ í† í”½ìœ¼ë¡œ ë‹¤ì‹œ ìƒì‚°í•˜ëŠ” ë©”ì‹œì§€ ì˜¤í”„ì…‹ì„ ì¶”ì í•˜ëŠ” ë° ì‚¬ìš©

**ì»¨ìŠˆë¨¸ ì¸í„°ì…‰í„°**
- ì»¨ìŠˆë¨¸ ì¸í„°ì…‰í„°ëŠ” ê°€ë¡œì±„ê¸°ë¥¼ ìœ„í•´ ë‘ ê°€ì§€ ì ‘ê·¼ì ì„ ì œê³µ

1ï¸âƒ£ `ConsumerInterceptor.onConsume()`
- ë¸Œë¡œì»¤ì—ì„œ ì¡°íšŒí•œ ì‹œì ê³¼ `Consumer.poll()` ë©”ì†Œë“œê°€ ë©”ì‹œì§€ë¥¼ ë°˜í™˜í•˜ê¸° ì „ `ConsumerRecords`ì—ì„œ ì½ëŠ”ë‹¤.
- `ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG`ë¥¼ í†µí•´ í•˜ë‚˜ ì´ìƒì˜ `ConsumerInterceptor` êµ¬í˜„ì í´ë˜ìŠ¤ì˜ ì»¬ë ‰ì…˜ìœ¼ë¡œ ì§€ì •

```java
ConsumerRecords<String, String> poll(long timeout) {
  ConsumerRecords<String, String> consumerRecords = 
    ...consuming records
  // ì¸í„°ì…‰í„° ì²´ì¸ì„ í†µí•´ ë ˆì½”ë“œë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í—Œ
  return interceptors.onConsume(consumerRecords);
}
```
  
2ï¸âƒ£ `ConsumerInterceptor.onCommit()`
- ì»¨ìŠˆë¨¸ê°€ ë¸Œë¡œì»¤ì—ê²Œ ì˜¤í”„ì…‹ì„ ì»¤ë°‹í•˜ë©´ ë¸Œë¡œì»¤ëŠ” í† í”½, íŒŒí‹°ì…˜ ë° ì»¤ë°‹ëœ ì˜¤í”„ì…‹ê³¼ ê´€ë ¨ëœ ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ ì •ë³´ê°€ í¬í•¨ëœ `Map<TopicPartition, OffsetAndMetadata>`ë¥¼ ë°˜í™˜

**ë¡œê¹… ëª©ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ê°„ë‹¨í•œ ConsumerInterceptor ì˜ˆì‹œ**

```java
// StockTransactionConsumerInterceptor.java

public class StockTransactionConsumerInterceptor implements ConsumerInterceptor<Object, Object> {
    //...

    /**
     * ë ˆì½”ë“œê°€ ì²˜ë¦¬ë˜ê¸° ì „ì— ì»¨ìŠˆë¨¸ ë ˆì½”ë“œì™€ ë©”íƒ€ë°ì´í„°ë¥¼ ë¡œê¹…
     */
    @Override
    public ConsumerRecords<Object, Object> onConsume(ConsumerRecords<Object, Object> consumerRecords) {
        LOG.info("Intercepted ConsumerRecords {}", buildMessage(consumerRecords.iterator()));
        return consumerRecords;
    }

    /**
     * ì¹´í”„ì¹´ ìŠ¤íŠ¸ë¦¼ì¦ˆ ì»¨ìŠˆë¨¸ê°€ ë¸Œë¡œì»¤ì— ì˜¤í”„ì…‹ì„ ì»¤ë°‹í•  ë•Œ ì»¤ë°‹ ì •ë³´ë¥¼ ë¡œê¹…
     */
    @Override
    public void onCommit(Map<TopicPartition, OffsetAndMetadata> map) {
        LOG.info("Commit information {}", map);
    }
    //...
}
```

**í”„ë¡œë“€ì„œ ì¸í„°ì…‰í„°**
- `ProducerInterceptor.onSend()` ë° `ProducerInterceptor.onAcknowledgement()` ë‘ ê°€ì§€ ì ‘ê·¼ ì§€ì ì´ ì¡´ì¬
- ì²´ì¸ìƒì— ìˆëŠ” ê° í”„ë¡œë“€ì„œ ì¸í„°ì…‰í„°ëŠ” ì´ì „ ì¸í„°ì…‰í„°ì—ì„œ ë°˜í™˜ëœ ê°ì²´ë¥¼ ë°›ëŠ”ë‹¤.

**ê°„ë‹¨íˆ ë¡œê¹…í•˜ëŠ” ProducerInterceptor ì˜ˆì œ**

```java
// ZMartProducerInterceptor.java

public class ZMartProducerInterceptor implements ProducerInterceptor<Object, Object> {
    /**
     * ë©”ì‹œì§€ë¥¼ ë¸Œë¡œì»¤ì— ì „ì†¡í•˜ê¸° ë°”ë¡œ ì „ì— ë¡œê¹…
     */
    @Override
    public ProducerRecord<Object, Object> onSend(ProducerRecord<Object, Object> record) {
        LOG.info("ProducerRecord being sent out {} ", record);
        return record;
    }

    /**
     * ë¸Œë¡œì»¤ ìˆ˜ì‹  í™•ì¸ ë˜ëŠ” ìƒì‚° ë‹¨ê³„ ë™ì•ˆ ë¸Œë¡œì»¤ ì¸¡ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆëŠ”ì§€ ë¡œê¹…
     */
    @Override
    public void onAcknowledgement(RecordMetadata metadata, Exception exception) {
        if (exception != null) {
            LOG.warn("Exception encountered producing record {}", exception);
        } else {
            LOG.info("record has been acknowledged {} ", metadata);
        }
    }
}
```

- ProducerInterceptorëŠ” ProducerConfig.INTERCEPTOR_CLASSES_CONFIGì— ì§€ì •í•˜ê³ , í•˜ë‚˜ ì´ìƒì˜ ProducerInterceptor í´ë˜ìŠ¤ì˜ ì»¬ë ‰ì…˜ìœ¼ë¡œ ì„¤ì •

âœ… ì°¸ê³ 

> ì¹´í”„ì¹´ ìŠ¤íŠ¸ë¦¼ì¦ˆ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì¸í„°ì…‰í„°ë¥¼ êµ¬ì„±í•  ë•Œ ì»¨ìŠˆë¨¸ì™€ í”„ë¡œë“€ì„œ ì¸í„°ì…‰í„°ì˜ ì†ì„± ì´ë¦„ì˜ í”„ë¦¬í”½ìŠ¤ë¥¼
>
> `StreamsConfig.consumerPrefix(ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG)` ì™€
>
> `StreamsConfig.producerPrefix(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG)` ë¡œ ì§€ì •í•´ì•¼ í•œë‹¤.

ë¶€ìˆ˜ì ìœ¼ë¡œ ì¸í„°ì…‰í„°ëŠ” ì¹´í”„ì¹´ ìŠ¤íŠ¸ë¦¼ì¦ˆ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ëª¨ë“  ë ˆì½”ë“œì—ì„œ ì‘ë™í•˜ë¯€ë¡œ ë¡œê¹… ì¸í„°ì…‰í„°ì˜ ì¶œë ¥ì´ ì¤‘ìš”í•˜ë‹¤.
- ì¸í„°ì…‰í„° ê²°ê³¼ëŠ” ì†ŒìŠ¤ ì½”ë“œë¥¼ ì„¤ì¹˜í•œ ë¡œê·¸ ë””ë ‰í† ë¦¬ì— ìˆëŠ” consumer_interceptor.log ë° producer_interceptor.log ë¡œ ì¶œë ¥

## ì• í”Œë¦¬ì¼€ì´ì…˜ ë©”íŠ¸ë¦­

ë©”íŠ¸ë¦­ ì¹´í…Œê³ ë¦¬ ì‚´í´ë³´ê¸°
- ìŠ¤ë ˆë“œ ë©”íŠ¸ë¦­
  - í‰ê·  ì»¤ë°‹, í´ë§, ì²˜ë¦¬ ì‘ì—… ì‹œê°„
  - ì´ˆë‹¹ ìƒì„±í•œ íƒœìŠ¤í¬ ìˆ˜, ì´ˆë‹¹ ì¢…ë£Œëœ íƒœìŠ¤í¬ ìˆ˜
- íƒœìŠ¤í¬ ë©”íŠ¸ë¦­
  - ì´ˆë‹¹ í‰ê·  ì»¤ë°‹ íšŸìˆ˜
  - í‰ê·  ì»¤ë°‹ ì‹œê°„
- í”„ë¡œì„¸ì„œ ë…¸ë“œ ë©”íŠ¸ë¦­
  - í‰ê·  ë° ìµœëŒ€ ì²˜ë¦¬ ì‹œê°„
  - ì´ˆë‹¹ í‰ê·  ì²˜ë¦¬ ì‘ì—… ìˆ˜
  - í¬ì›Œë“œ ë ˆì´íŠ¸
- ìƒíƒœ ì €ì¥ì†Œ ë©”íŠ¸ë¦­
  - put, get, flush ì‘ì—…ì˜ í‰ê·  ì‹¤í–‰ ì‹œê°„
  - put, get, flush ì‘ì—…ì˜ ì´ˆë‹¹ í‰ê·  ì‹¤í–‰ íšŸìˆ˜

[Monitor Kafka Streams Applications in Confluent](https://docs.confluent.io/platform/current/streams/monitoring.html#)

.

ğŸ‘‰ğŸ» **ë©”íŠ¸ë¦­ êµ¬ì„±**
- ì¹´í”„ì¹´ ìŠ¤íŠ¸ë¦¼ì¦ˆëŠ” ì´ë¯¸ ì„±ëŠ¥ ë©”íŠ¸ë¦­ì„ ìˆ˜ì§‘í•˜ëŠ” ë©”ì»¤ë‹ˆì¦˜ì„ ì œê³µ

ì„¤ì •í•œ ë ˆë²¨ì— ë”°ë¥¸ ê°„ìœ¼í•œ ë©”íŠ¸ë¦­
- ë©”íŠ¸ë¦­ ìˆ˜ì§‘ì˜ ê¸°ë³¸ ë ˆë²¨ì€ INFO

|ë§¤íŠ¸ë¦­ ì¹´í…Œê³ ë¦¬|DEBUG|INFO|
|---|---|---|
|ìŠ¤ë ˆë“œ|O|O|
|íƒœìŠ¤í¬|O||
|í”„ë¡œì„¸ì„œ ë…¸ë“œ|O||
|ìƒíƒœ ì €ì¥ì†Œ|O||
|ë ˆì½”ë“œ ìºì‹œ|O||

ë©”íŠ¸ë¦­ì„ ìœ„í•œ êµ¬ì„± ë³€ê²½

```java
private static Properties getProperties() {
    Properties props = new Properties();
    props.put(StreamsConfig.CLIENT_ID_CONFIG, "zmart-metrics-client-id"); // í´ë¼ì´ì–¸íŠ¸ ì•„ì´ë””
    props.put(ConsumerConfig.GROUP_ID_CONFIG, "zmart-metrics-group-id"); // ê·¸ë£¹ ì•„ì´ë””
    props.put(StreamsConfig.APPLICATION_ID_CONFIG, "zmart-metrics-application-id"); // ì• í”Œë¦¬ì¼€ì´ì…˜ ì•„ì´ë””
    props.put(StreamsConfig.METRICS_RECORDING_LEVEL_CONFIG, "DEBUG"); // ë©”íŠ¸ë¦­ ë¡œê·¸ ë ˆë²¨
    props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092"); // ë¸Œë¡œì»¤ ì ‘ì† ì„¤ì •
    props.put(StreamsConfig.producerPrefix(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG), Collections.singletonList(ZMartProducerInterceptor.class));
    return props;
}
```

- ì¹´í”„ì¹´ ìŠ¤íŠ¸ë¦¼ì¦ˆ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì „ì²´ ë²”ìœ„ë¥¼ ì¸¡ì •í•˜ëŠ” ê¸°ë³¸ ë©”íŠ¸ë¦­ì´ ìˆìœ¼ë©°, DEBUG ë ˆë²¨ì—ì„œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ì„ ì„¤ì •í•˜ë ¤ë©´ ê·¸ ì „ì— ì„±ëŠ¥ ì˜í–¥ì„ ì‹ ì¤‘í•˜ê²Œ ê³ ë ¤í•´ì•¼ í•¨

.

ğŸ‘‰ğŸ» **ìˆ˜ì§‘í•œ ë©”íŠ¸ë¦­ í™•ì¸ ë°©ë²•**
- ì¹´í”„ì¹´ ìŠ¤íŠ¸ë¦¼ì¦ˆ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ë©”íŠ¸ë¦­ì„ ìˆ˜ì§‘í•˜ë©´ ë©”íŠ¸ë¦­ ë¦¬í¬í„°ì—ê²Œ ë°°í¬
- ê¸°ë³¸ ë©”íŠ¸ë¦­ ë¦¬í¬í„°ë¥¼ JMX(Java Management Extensions)ë¥¼ í†µí•´ ì œê³µ
- ë©”íŠ¸ë¦­ ì ‘ê·¼ ì˜ˆì œ
  - [StockPerformanceStreamsAndProcessorMetricsApplication.java](https://github.com/bbejeck/kafka-streams-in-action/blob/master/src/main/java/bbejeck/chapter_7/StockPerformanceStreamsAndProcessorMetricsApplication.java)

.

ğŸ‘‰ğŸ» **JMX(Java Management Extensions) ì‚¬ìš©**
- ìë°” VMì—ì„œ ì‹¤í–‰ë˜ëŠ” í”„ë¡œê·¸ë¨ì˜ ë™ì‘ì„ ë³´ëŠ” í‘œì¤€ ë°©ë²•
- JMXë¥¼ ì‚¬ìš©í•´ ìë°” VM ì„±ëŠ¥ë„ í™•ì¸ ê°€ëŠ¥
- ì¦‰, JMXëŠ” ì‹¤í–‰ ì¤‘ì¸ í”„ë¡œê·¸ë¨ì˜ ì¼ë¶€ë¥¼ ë…¸ì¶œí•˜ëŠ” ì¸í”„ë¼ë¥¼ ì œê³µ
- ëª¨ë‹ˆí„°ë§ ìˆ˜í–‰ì„ ìœ„í•´ [VisualVM](https://visualvm.github.io/), [JConsole](https://docs.oracle.com/en/java/javase/13/management/using-jconsole.html#GUID-77416B38-7F15-4E35-B3D1-34BFD88350B5), [JMC](https://docs.oracle.com/javacomponents/jmc-5-5/jmc-user-guide/jmc.htm#JMCCI111) ì‚¬ìš©

## ì¶”ê°€ì ì¸ ì¹´í”„ì¹´ ìŠ¤íŠ¸ë¦¼ì¦ˆ ë””ë²„ê¹… ê¸°ìˆ 

ğŸ‘‰ğŸ» **ì• í”Œë¦¬ì¼€ì´ì…˜ êµ¬ì¡° ì¡°íšŒ**
- `Topology.describe()` ë©”ì†Œë“œëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ êµ¬ì¡°ì— ê´€í•œ ì¼ë°˜ì ì¸ ì •ë³´ë¥¼ ì œê³µ

![Result](https://github.com/jihunparkme/jihunparkme.gitbook.io/blob/main/.gitbook/assets/kafka-streams-in-action/toStringExample.jpg?raw=trueÂ 'Result')

- ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì‹¤í–‰ ì‹œê°„ ì •ë³´ë¥¼ ë³´ì—¬ì£¼ëŠ” `StreamThread` ê°ì²´ì— ê´€í•œ ì •ë³´ë¥¼ ì–»ëŠ” ê²ƒë„ ìœ ìš©
  - KafkaStreams.localThreadsMetadata() ë©”ì†Œë“œ ì‚¬ìš©

.

ğŸ‘‰ğŸ» **ë‹¤ì–‘í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒíƒœ ì•Œë¦¼ ë°›ê¸°**

**`StateListener` ì‚¬ìš©**
- ì¹´í”„ì¹´ ìŠ¤íŠ¸ë¦¼ì¦ˆ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ê°€ëŠ¥í•œ ì—¬ì„¯ ê°€ì§€ ìœ íš¨í•œ ìƒíƒœë¥¼ ë³´ì—¬ì¤€ë‹¤.

ì¹´í”„ì¹´ ìŠ¤íŠ¸ë¦¼ì¦ˆ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ìƒíƒœ

![Result](https://github.com/jihunparkme/jihunparkme.gitbook.io/blob/main/.gitbook/assets/kafka-streams-in-action/updatedStates.jpg?raw=trueÂ 'Result')

```java
// ZMartKafkaStreamsAdvancedReqsMetricsApp.java

KafkaStreams.StateListener stateListener = (newState, oldState) -> {
    // REBALANCING ì—ì„œ RUNNING ìœ¼ë¡œ ìƒíƒœ ì „í™˜
    if (newState == KafkaStreams.State.RUNNING && oldState == KafkaStreams.State.REBALANCING) {
        LOG.info("Application has gone from REBALANCING to RUNNING ");
        LOG.info("Topology Layout {}", streamsBuilder.build().describe());
    }

    // REBALANCING ë‹¨ê³„ ì§„ì… ì‹œ ì•¡ì…˜
    if (newState == KafkaStreams.State.REBALANCING) {
        LOG.info("Application is entering REBALANCING phase");
    }
};
```

**ìƒíƒœ ë¦¬ìŠ¤í† ì–´ ë¦¬ìŠ¤ë„ˆ**
- ì¹´í”„ì¹´ ìŠ¤íŠ¸ë¦¼ì¦ˆì—ì„œëŠ” ìƒíƒœ ì €ì¥ì†Œì˜ ë°±ì—…ìœ¼ë¡œ `ë³€ê²½ë¡œê·¸` í† í”½ì„ ì‚¬ìš©
- ë³€ê²½ë¡œê·¸ëŠ” ë³€ê²½ì´ ë°œìƒí•œ ìƒíƒœ ì €ì¥ì†Œì˜ ì—…ë°ì´íŠ¸ë¥¼ ê¸°ë¡
- ì¹´í”„ì¹´ ìŠ¤íŠ¸ë¦¼ì¦ˆ ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ì‹¤íŒ¨í•˜ê±°ë‚˜ ì¬ì‹œì‘í•  ë•Œ, ìƒíƒœ ì €ì¥ì†ŒëŠ” ë¡œì»¬ ìƒíƒœ íŒŒì¼ì—ì„œ ë³µêµ¬ ê°€ëŠ¥
- StateListenerì™€ í¡ì‚¬í•œ `StateRestoreListener` ì¸í„°í˜ì´ìŠ¤ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ ë‚´ë¶€ì—ì„œ ì¼ì–´ë‚˜ëŠ” ì¼ë“¤ì— ëŒ€í•œ ì•Œë¦¼ì„ í—ˆìš©
  - `onRestoreStart`, `onBatchRestored`, `onRestoreEnd` ì„¸ ê°€ì§€ ë©”ì†Œë“œ ì¡´ì¬

```java
// LoggingStateRestoreListener.java

public class LoggingStateRestoreListener implements StateRestoreListener {
    private static final Logger LOG = LoggerFactory.getLogger(LoggingStateRestoreListener.class);
    private final Map<TopicPartition, Long> totalToRestore = new ConcurrentHashMap<>();
    private final Map<TopicPartition, Long> restoredSoFar = new ConcurrentHashMap<>();

    /**
     * ë¦¬ìŠ¤í† ì–´ ë¦¬ìŠ¤ë„ˆ ë¡œê¹…
     */
    @Override
    public void onRestoreStart(TopicPartition topicPartition, String store, long start, long end) {
        long toRestore = end - start;
        totalToRestore.put(topicPartition, toRestore); // ë³µì›í•  ì£¼ì–´ì§„ topicPartition ì´ëŸ‰ ì €ì¥
        LOG.info("Starting restoration for {} on topic-partition {} total to restore {}", store, topicPartition, toRestore);

    }
    /**
     * ë³µì›ëœ ê° ë°°ì¹˜ë¥¼ ì²˜ë¦¬
     */
    @Override
    public void onBatchRestored(TopicPartition topicPartition, String store, long start, long batchCompleted) {
        NumberFormat formatter = new DecimalFormat("#.##");

        long currentProgress = batchCompleted + restoredSoFar.getOrDefault(topicPartition, 0L); // ë³µì›ëœ ì „ì²´ ë ˆì½”ë“œ ê°œìˆ˜ ê³„ì‚°
        double percentComplete = (double) currentProgress / totalToRestore.get(topicPartition); // ë³µì›ì´ ì™„ë£Œëœ ë°±ë¶„ìœ¨ì„ ê²°ì •

        LOG.info("Completed {} for {}% of total restoration for {} on {}",
                batchCompleted, formatter.format(percentComplete * 100.00), store, topicPartition); // ë³µì›ëœ ë°±ë¶„ìœ¨ì„ ì¶œë ¥
        restoredSoFar.put(topicPartition, currentProgress); // ì§€ê¸ˆê¹Œì§€ ë³µì›ëœ ë ˆì½”ë“œ ê°œìˆ˜ ì €ì¥
    }
    /**
     * ë³µì› í”„ë¡œì„¸ìŠ¤ê°€ ì™„ë£Œë  ë•Œ
     */
    @Override
    public void onRestoreEnd(TopicPartition topicPartition, String store, long totalRestored) {
        LOG.info("Restoration completed for {} on topic-partition {}", store, topicPartition);
        restoredSoFar.put(topicPartition, 0L);
    }
}

// CoGroupingListeningExampleApplication.java
KafkaStreams kafkaStreams = new KafkaStreams(topology, streamsConfig);
kafkaStreams.setGlobalStateRestoreListener(new LoggingStateRestoreListener()); // ê¸€ë¡œë²Œ ë¦¬ìŠ¤í† ì–´ ë¦¬ìŠ¤ë„ˆ ì •ì˜
```

- ë‚´ë¶€ ì»¨ìŠˆë¨¸ë¥¼ ì‚¬ìš©í•´ ë²ˆê²½ë¡œê·¸ í† í”½ì„ ì½ìœ¼ë¯€ë¡œ ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ê° consumer.poll() ë©”ì†Œë“œ í˜¸ì¶œì—ì„œ ë ˆì½”ë“œë¥¼ ì¼ê´„ì ìœ¼ë¡œ ë³µì›
- ë³µì› í”„ë¡œì„¸ìŠ¤ê°€ ìµœê·¼ ë°°ì¹˜ë¥¼ ìƒíƒœ ì €ì¥ì†Œì— ë¡œë“œí•œ í›„ `onBatchRestored` ë©”ì†Œë“œê°€ í˜¸ì¶œ
- ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ë³µêµ¬ í”„ë¡œì„¸ìŠ¤ë¥¼ ì™„ë£Œí•˜ë©´ ë³µì›ëœ ë§ˆì§€ë§‰ ë¦¬ìŠ¤ë„ˆë¥¼ ì´ ë ˆì½”ë“œ ìˆ˜ì™€ í•¨ê»˜ í˜¸ì¶œ

**uncaught ì˜ˆì™¸ í•¸ë“¤ëŸ¬**
- ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ ì²˜ë¦¬ë¥¼ ìœ„í•´ `KafkaStreams.setUncaughtExceptionHandler` ì œê³µ

```java
// CoGroupingListeningExampleApplication.java

kafkaStreams.setUncaughtExceptionHandler((thread, exception) ->
    LOG.error("Thread [{}] encountered [{}]", thread.getName(), exception.getMessage())
);
```

ğŸ“– **ìš”ì•½**

> ì¹´í”„ì¹´ ìŠ¤íŠ¸ë¦¼ì¦ˆë¥¼ ëª¨ë‹ˆí„°ë§í•˜ë ¤ë©´ ì¹´í”„ì¹´ ë¸Œë¡œì»¤ë„ ì‚´í´ë´ì•¼ í•œë‹¤.
>
> ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì„±ëŠ¥ì´ ì–´ë–»ê²Œ ë˜ëŠ”ì§€ ë³´ê³  ì‹¶ë‹¤ë©´ ë©”íŠ¸ë¦­ ë¦¬í¬íŒ…ì„ ìˆ˜ì‹œë¡œ í™œì„±í™”í•´ì•¼ í•œë‹¤.
>
> ë‚´ë¶€ë¥¼ ì‚´í´ë³¼ í•„ìš”ê°€ ìˆìœ¼ë©° ê°€ë” `jstack`(ìŠ¤ë ˆë“œ ë¤í”„)ê³¼ `jmap/jhat`(í™ ë¤í”„) ê°™ì€ ìë°”ì— í¬í•¨ëœ ëª…ë ¹ì¤„ ë„êµ¬ë¥¼ ì‚¬ìš©í•´ ì¢€ ë” ì € ìˆ˜ì¤€ì—ì„œ ì• í”Œë¦¬ì¼€ì´ì…˜ ë™ì‘ì„ ì´í•´í•´ì•¼ í•œë‹¤.

# 8ì¥. ì¹´í”„ì¹´ ìŠ¤íŠ¸ë¦¼ì¦ˆ ì• í”Œë¦¬ì¼€ì´ì…˜ í…ŒìŠ¤íŠ¸

## í† í´ë¡œì§€ í…ŒìŠ¤íŠ¸

`ProcessorTopologyTestDriver`ë¥¼ ì‚¬ìš©í•˜ë©´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ì„ ìœ„í•´ ì¹´í”„ì¹´ ì—†ì´ë„ í…ŒìŠ¤íŠ¸ ì‘ì„±ì´ ê°€ëŠ¥

```properties
testImplementation("org.apache.kafka:kafka-streams:1.0.0")
testImplementation("org.apache.kafka:kafka-clients:1.0.0")
```

```java
// ZMartTopology.java

public class ZMartTopology {
    public static Topology build() {
        Serde<Purchase> purchaseSerde = StreamsSerdes.PurchaseSerde();
        Serde<PurchasePattern> purchasePatternSerde = StreamsSerdes.PurchasePatternSerde();
        Serde<RewardAccumulator> rewardAccumulatorSerde = StreamsSerdes.RewardAccumulatorSerde();
        Serde<String> stringSerde = Serdes.String();

        StreamsBuilder streamsBuilder = new StreamsBuilder();
        KStream<String, Purchase> purchaseKStream = streamsBuilder.stream("transactions", Consumed.with(stringSerde, purchaseSerde))
                .mapValues(p -> Purchase.builder(p).maskCreditCard().build());
        KStream<String, PurchasePattern> patternKStream = purchaseKStream.mapValues(purchase -> PurchasePattern.builder(purchase).build());
        patternKStream.to("patterns", Produced.with(stringSerde, purchasePatternSerde));
        KStream<String, RewardAccumulator> rewardsKStream = purchaseKStream.mapValues(purchase -> RewardAccumulator.builder(purchase).build());

        rewardsKStream.to("rewards", Produced.with(stringSerde, rewardAccumulatorSerde));
        purchaseKStream.to("purchases", Produced.with(Serdes.String(), purchaseSerde));

        return streamsBuilder.build();
    }
}
```

.

ğŸ‘‰ğŸ» **í…ŒìŠ¤íŠ¸ ë§Œë“¤ê¸°**

```java
// ZMartTopologyTest.java

public class ZMartTopologyTest {
    private ProcessorTopologyTestDriver topologyTestDriver;

    @BeforeEach
    public void setUp() {
        Properties props = new Properties();
        props.put(StreamsConfig.CLIENT_ID_CONFIG, "FirstZmart-Kafka-Streams-Client");
        props.put(ConsumerConfig.GROUP_ID_CONFIG, "zmart-purchases");
        props.put(StreamsConfig.APPLICATION_ID_CONFIG, "FirstZmart-Kafka-Streams-App");
        props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        props.put(StreamsConfig.REPLICATION_FACTOR_CONFIG, 1);
        props.put(StreamsConfig.DEFAULT_TIMESTAMP_EXTRACTOR_CLASS_CONFIG, WallclockTimestampExtractor.class);

        StreamsConfig streamsConfig = new StreamsConfig(props);
        Topology topology = ZMartTopology.build(); // í† í´ë¡œì§€ íšë“

        // ProcessorTopologyTestDriver ìƒì„±
        topologyTestDriver = new ProcessorTopologyTestDriver(streamsConfig, topology); 
    }


    @Test
    @DisplayName("Testing the ZMart Topology Flow")
    public void testZMartTopology() {
        Serde<Purchase> purchaseSerde = StreamsSerdes.PurchaseSerde();
        Serde<PurchasePattern> purchasePatternSerde = StreamsSerdes.PurchasePatternSerde();
        Serde<RewardAccumulator> rewardAccumulatorSerde = StreamsSerdes.RewardAccumulatorSerde();
        Serde<String> stringSerde = Serdes.String();

        // í…ŒìŠ¤íŠ¸ ê°ì²´ ìƒì„±
        Purchase purchase = DataGenerator.generatePurchase();
        // í† í´ë¡œì§€ì— ì´ˆê¸° ë ˆì½”ë“œ ì „ì†¡
        topologyTestDriver.process("transactions",
                null,
                purchase,
                stringSerde.serializer(),
                purchaseSerde.serializer());
        // ë ˆì½”ë“œ ì½ê¸°
        ProducerRecord<String, Purchase> record = topologyTestDriver.readOutput("purchases",
                stringSerde.deserializer(),
                purchaseSerde.deserializer());
        // í…ŒìŠ¤íŠ¸ ê°ì²´ë¥¼ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        Purchase expectedPurchase = Purchase.builder(purchase).maskCreditCard().build();
        // í† í´ë¡œì§€ë¡œë¶€í„° ë ˆì½”ë“œê°€ ê¸°ëŒ€í•˜ëŠ” ë ˆì½”ë“œì™€ ì¼ì¹˜í•˜ëŠ”ì§€ ê²€ì‚¬
        assertThat(record.value(), equalTo(expectedPurchase));

        RewardAccumulator expectedRewardAccumulator = RewardAccumulator.builder(expectedPurchase).build();

        ProducerRecord<String, RewardAccumulator> accumulatorProducerRecord = 
            topologyTestDriver.readOutput("rewards", // rewards í† í”½ì—ì„œ ë ˆì½”ë“œ ì½ê¸°
                stringSerde.deserializer(),
                rewardAccumulatorSerde.deserializer());

        assertThat(accumulatorProducerRecord.value(), equalTo(expectedRewardAccumulator)); // rewards í† í”½ ì¶œë ¥ê³¼ ê¸°ëŒ“ê°’ì„ ë¹„êµ

        PurchasePattern expectedPurchasePattern = PurchasePattern.builder(expectedPurchase).build();

        ProducerRecord<String, PurchasePattern> purchasePatternProducerRecord = 
              topologyTestDriver.readOutput("patterns", // patterns í† í”½ì—ì„œ ë ˆì½”ë“œ ì½ê¸°
                stringSerde.deserializer(),
                purchasePatternSerde.deserializer());

        assertThat(purchasePatternProducerRecord.value(), equalTo(expectedPurchasePattern)); // patterns í† í”½ ì¶œë ¥ê³¼ ê¸°ëŒ“ê°’ ë¹„êµ
    }
}
```